{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version : 3.6.8 |Anaconda custom (64-bit)| (default, Dec 30 2018, 01:22:34) \n",
      "[GCC 7.3.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load systems\n",
    "import sys\n",
    "print(\"Python version : {}\". format(sys.version))\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape :  (42000, 28, 28, 1)\n",
      "y_train shape :  (42000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('./input/train.csv').values\n",
    "test_data = pd.read_csv('./input/test.csv').values\n",
    "\n",
    "\n",
    "x_train = train_data[:, 1:].reshape(train_data.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255.0\n",
    "\n",
    "x_test = test_data.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255.0\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(train_data[:, 0], 10)\n",
    "\n",
    "print(\"x_train shape : \", x_train.shape)\n",
    "print(\"y_train shape : \", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet 代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "class LeNet5:\n",
    "    \"\"\" LeNet-5\n",
    "\n",
    "        input : 28 * 28\n",
    "        C1 : 6 feature maps, kernel size 5*5, activation relu\n",
    "        S2 : 6 feature maps, pooling size 2*2, maxpooling\n",
    "        C3 : 16 feature maps, kernel size 5*5, activation relu\n",
    "        S4 : 16 feature maps, pooling size 2*2, maxpooling\n",
    "        C5 : 120 feature maps, kernel size 5*5, activation relu\n",
    "        F6 : 84\n",
    "        output : 10\n",
    "\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def build():\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(ZeroPadding2D(padding=(2, 2), input_shape = (28, 28, 1)))\n",
    "\n",
    "        # C1\n",
    "        model.add(Conv2D(filters = 6, kernel_size = (5, 5), \n",
    "            strides = (1, 1), activation = 'relu' ))\n",
    "\n",
    "        # S2\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "        # C3\n",
    "        # TODO:\n",
    "        model.add(Conv2D(filters = 16, kernel_size = (5, 5),            \n",
    "            strides = (1, 1), activation = 'relu'))\n",
    "\n",
    "        # S4\n",
    "        model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "        # C5\n",
    "        model.add(Conv2D(filters = 120, kernel_size = (5, 5),            \n",
    "            strides = (1, 1), activation = 'relu'))\n",
    "\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # F6\n",
    "        model.add(Dense(units = 84, activation = 'relu'))\n",
    "\n",
    "        # output\n",
    "        model.add(Dense(units = 10, activation = 'softmax'))\n",
    "\n",
    "        model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "33600/33600 [==============================] - 12s 358us/step - loss: 0.4148 - acc: 0.8660\n",
      "Epoch 2/20\n",
      "33600/33600 [==============================] - 12s 349us/step - loss: 0.0932 - acc: 0.9712\n",
      "Epoch 3/20\n",
      "33600/33600 [==============================] - 10s 306us/step - loss: 0.0655 - acc: 0.9797\n",
      "Epoch 4/20\n",
      "33600/33600 [==============================] - 11s 332us/step - loss: 0.0505 - acc: 0.9838\n",
      "Epoch 5/20\n",
      "33600/33600 [==============================] - 10s 311us/step - loss: 0.0420 - acc: 0.9866\n",
      "Epoch 6/20\n",
      "33600/33600 [==============================] - 15s 439us/step - loss: 0.0349 - acc: 0.9885\n",
      "Epoch 7/20\n",
      "33600/33600 [==============================] - 12s 360us/step - loss: 0.0287 - acc: 0.9904\n",
      "Epoch 8/20\n",
      "33600/33600 [==============================] - 12s 360us/step - loss: 0.0241 - acc: 0.9923\n",
      "Epoch 9/20\n",
      "33600/33600 [==============================] - 12s 343us/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 10/20\n",
      "33600/33600 [==============================] - 11s 341us/step - loss: 0.0173 - acc: 0.9942\n",
      "Epoch 11/20\n",
      "33600/33600 [==============================] - 12s 345us/step - loss: 0.0157 - acc: 0.9946\n",
      "Epoch 12/20\n",
      "33600/33600 [==============================] - 12s 372us/step - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 13/20\n",
      "33600/33600 [==============================] - 15s 441us/step - loss: 0.0105 - acc: 0.9965\n",
      "Epoch 14/20\n",
      "33600/33600 [==============================] - 13s 381us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 15/20\n",
      "33600/33600 [==============================] - 13s 373us/step - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 16/20\n",
      "33600/33600 [==============================] - 13s 391us/step - loss: 0.0081 - acc: 0.9974\n",
      "Epoch 17/20\n",
      "33600/33600 [==============================] - 13s 384us/step - loss: 0.0053 - acc: 0.9985\n",
      "Epoch 18/20\n",
      "33600/33600 [==============================] - 11s 335us/step - loss: 0.0053 - acc: 0.9985\n",
      "Epoch 19/20\n",
      "33600/33600 [==============================] - 10s 309us/step - loss: 0.0048 - acc: 0.9984\n",
      "Epoch 20/20\n",
      "33600/33600 [==============================] - 11s 323us/step - loss: 0.0040 - acc: 0.9987\n",
      "8400/8400 [==============================] - 1s 129us/step\n",
      "[INFO] accuracy: 98.62%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "epochs = 20\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(x_train, y_train, test_size=0.2)\n",
    "\n",
    "model = LeNet5.build()\n",
    "\n",
    "model.fit(trainX, trainY, batch_size=128, epochs=epochs, verbose=1)\n",
    "\n",
    "(loss, accuracy) = model.evaluate(testX, testY, batch_size=128, verbose=1)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(x_test)\n",
    "labels = np.argmax(results, axis = 1)\n",
    "labels = pd.Series(labels, name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"), labels],axis = 1)\n",
    "\n",
    "submission.to_csv(\"./results/cnn_mnist_datagen.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3 keras",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
